# Research (Estimation): issue-124

---

## メタ情報

- 作成日: 2026-02-22
- 作成者: @opencode
- 対象: 見積もり前調査
- Issue: #124 llm: キャラクター/振る舞いの外部注入 + チャット出力長制限

---

## 1. 調査の目的

Issue #124 の見積もり前に、(1) persona 外部注入の実装境界、(2) `assistant_text` 長さ制限の多層ガード（モデル側/アプリ側）、(3) 決定論的テスト範囲を明確化し、工数レンジと信頼度をブレなく算定する。

---

## 2. 新規性判定（発火条件）

- 直接の先行事例が2件未満: No
- PRD/Epic/Issue に Unknown/曖昧さが残る: Yes
- Q6-5〜8（PII/監査/性能/可用性）のいずれかが Yes: Yes

---

## 3. 候補（必須: >= 5）

候補-1
概要: `server/src/providers/llm-provider.ts` の system prompt 合成を `persona + format/safety + length` の構成に置換する
適用可否: Yes
仮説: OpenAI互換/Gemini双方の固定文字列を共通合成関数へ寄せれば、重複と差分漏れを抑えて要件を満たせる
反証: follow-up 呼び出し（tool_calls 後）側の system prompt 更新漏れで挙動不一致が起きる
採否理由: Issue #124 の主目的そのものであり、既存コード（OpenAI/Geminiで各2箇所）に直接適用可能なため
根拠リンク:
- https://github.com/ToaruPen/Wooly-Fluffy/issues/124
- https://github.com/ToaruPen/Wooly-Fluffy/blob/main/server/src/providers/llm-provider.ts
捨て条件:
- providerごとに別persona方針（仕様差分）を新たに要求された場合
リスク/検証:
- リスク: 4箇所の片側更新漏れ
- 検証方法: `server/src/providers/llm-provider.test.ts` で OpenAI/Gemini 両方の prompt 構築を検証

候補-2
概要: `LLM_CHAT_MAX_OUTPUT_CHARS` を env から読み取り、`assistant_text` をアプリ側で clamp する
適用可否: Yes
仮説: 既存 `readEnvInt` + `clampString` パターンを流用すれば、低コストで決定論的制限が入る
反証: clamp が parse 前後の位置不整合で未適用となり、極端な長文が通過する
採否理由: 既存実装に同型パターン（session_summary の長さ制限）があり、最も確実に効果を出せるため
根拠リンク:
- https://github.com/ToaruPen/Wooly-Fluffy/blob/main/server/src/env.ts
- https://github.com/ToaruPen/Wooly-Fluffy/blob/main/server/src/providers/llm-provider.ts
捨て条件:
- PRD/Epic 側で文字数制限ではなく文数制限へ要件変更が入った場合
リスク/検証:
- リスク: env 未設定時のデフォルト値妥当性
- 検証方法: `server/src/providers/llm-provider.test.ts` と `server/src/env.test.ts` の env系テストで固定

候補-3
概要: Gemini JSON schema の `assistant_text` に `maxLength` を追加しモデル側制約を併用する
適用可否: Yes
仮説: schema 制約を与えることで、アプリ側 clamp 前の生成過多を一定抑制できる
反証: schema が chat 経路で渡っておらず、実際のモデル出力長に影響しない
採否理由: model-side/app-side の二重ガード要件に合致し、既存 schema 実装に追記だけで実現できるため
根拠リンク:
- https://github.com/ToaruPen/Wooly-Fluffy/blob/main/server/src/providers/llm-provider.ts
- https://ai.google.dev/gemini-api/docs/structured-output
捨て条件:
- Gemini SDK 側仕様変更で chat の response schema が使えないと判明した場合
リスク/検証:
- リスク: schema 適用箇所の誤認
- 検証方法: Gemini モック経由で `responseJsonSchema` 内容をテストで検証

候補-4
概要: persona を file-based で読み込み、`WOOLY_FLUFFY_PERSONA_PATH` 上書き + default path を持つ loader を新設する
適用可否: Yes
仮説: `local-env.ts` の依存注入パターンを踏襲すれば、watch/reload を含めても決定論的にテストできる
反証: `no-restricted-imports` 制約と watch 実装が衝突し、実装が複雑化する
採否理由: Issue 合意済み設計（YAML + persona.md、chokidar watch）に整合するため
根拠リンク:
- https://github.com/ToaruPen/Wooly-Fluffy/issues/124
- https://github.com/ToaruPen/Wooly-Fluffy/blob/main/server/src/local-env.ts
- https://github.com/paulmillr/chokidar
捨て条件:
- #125（依存追加）が未完了で chokidar/yaml/valibot 利用ができない場合
リスク/検証:
- リスク: mtime/watch の非決定性
- 検証方法: loader 依存注入テストで mtime 変化とリロードを固定

候補-5
概要: persona サイズ上限（例: 10KB）超過時に安全側フォールバックする
適用可否: Partial
仮説: サイズ上限で極端な prompt 肥大化を予防できる
反証: 上限値の根拠が不十分で、通常運用の persona を不必要に拒否する
採否理由: 安全性上は有効だが、しきい値決定は運用要件依存のため Partial 採用が妥当
根拠リンク:
- https://github.com/ToaruPen/Wooly-Fluffy/issues/124
捨て条件:
- 運用側が上限管理を不要と判断した場合
リスク/検証:
- リスク: 誤フォールバックで意図しないデフォルト人格になる
- 検証方法: しきい値境界（直下/直上）ユニットテストを追加

候補-6
概要: 依存追加（#125）の完了を前提に #124 見積もりを分離管理する
適用可否: Yes
仮説: prereq 未完了を明示すると見積もりの不確実性を減らせる
反証: #125 完了前提で見積もった内容が実際の依存状態と一致しない
採否理由: Issue 本文に Prereq 明記があり、見積もり前提として明文化すべきため
根拠リンク:
- https://github.com/ToaruPen/Wooly-Fluffy/issues/124
- https://github.com/ToaruPen/Wooly-Fluffy/issues/125
捨て条件:
- #125 がマージ済みで依存が main に反映済みの場合
リスク/検証:
- リスク: 依存未解決のまま実装開始
- 検証方法: `server/package.json` と `gh issue view 125` の状態確認を見積もり前提へ記載

---

## 4. 隣接領域探索（新規性が高い場合は必須）

隣接領域探索: N/A（主要変更は既存 provider/env/test パターンの拡張であり、新規アーキテクチャ導入はない）

---

## 5. 止め時（必須）

タイムボックス: 75min
打ち切り条件:
- 変更対象ファイル（実装/テスト）が特定でき、`assistant_text` 制限と persona 注入の検証方針が確定している
- 不確実性が「watch/reload境界」と「依存未完了」の2点に限定されている

---

## 6. 探索ログ（必須）

- 何を調べたか: `gh issue view 124`, `gh issue view 125`, `docs/prd/wooly-fluffy.md`, `docs/epics/wooly-fluffy-mvp-epic.md`, `server/src/providers/llm-provider.ts`, `server/src/providers/llm-provider.test.ts`, `server/src/local-env.ts`, `server/src/local-env.test.ts`, `server/src/session-buffer.ts`, `server/src/env.ts`
- 何を除外したか: web 側UI変更、DBマイグレーション、会話本文/音声/STT全文の保存に関わる設計変更（Issueスコープ外）
- 未解決: #125 が OPEN のため、chokidar/yaml/valibot を使う前提の実装工数には依存解決待ちリスクが残る

---

## 7. 見積もりへの反映サマリ

- 不確実性/リスク: prereq #125 未完了、watch/reload のテスト設計（mtime/event）
- 調査で減った不確実性: clamp/env/schema/prompt 合成は既存先例があり、実装・テスト対象が `llm-provider` 中心に収束
- テスト計画への影響: `llm-provider.test.ts` に (1) persona 注入、(2) `assistant_text` clamp、(3) Gemini schema `assistant_text.maxLength` 検証を追加し、必要に応じて loader 専用テストを分離する
